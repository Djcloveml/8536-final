{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from evaluate import load as evaluate_load\n",
    "from typing import Dict\n",
    "from torchvision import transforms as tv_transforms\n",
    "from transformers import (\n",
    "    \n",
    "    AutoImageProcessor,\n",
    "    AutoModelForImageClassification,\n",
    "    DefaultDataCollator,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "import wandb\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import random\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data():\n",
    "    dog = load_dataset(\"amaye15/stanford-dogs\")\n",
    "\n",
    "    labels = dog[\"train\"].features[\"label\"].names\n",
    "    label2id = {label: str(i) for i, label in enumerate(labels)}\n",
    "    id2label = {str(i): label for i, label in enumerate(labels)}\n",
    "\n",
    "    return dog, labels, label2id, id2label\n",
    "\n",
    "\n",
    "def get_image_transforms():\n",
    "    return tv_transforms.Compose(\n",
    "        [\n",
    "            tv_transforms.Resize((224, 224)),\n",
    "            tv_transforms.ToTensor(),\n",
    "            tv_transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "\n",
    "    predictions = predictions[0] if isinstance(predictions, tuple) else predictions\n",
    "    labels = labels[0] if isinstance(labels, tuple) else labels\n",
    "\n",
    "    predictions = torch.from_numpy(predictions)\n",
    "    labels = torch.from_numpy(labels)\n",
    "\n",
    "    # Get the predicted class\n",
    "    predicted_classes = predictions.argmax(dim=-1)\n",
    "\n",
    "    # Compute accuracy\n",
    "    correct = (predicted_classes == labels).float()\n",
    "    accuracy = correct.mean().item()\n",
    "\n",
    "    # Compute top-5 accuracy\n",
    "    top5_pred = predictions.topk(5, dim=-1)[1]\n",
    "    top5_correct = top5_pred.eq(labels.view(-1, 1).expand_as(top5_pred)).float()\n",
    "    top5_accuracy = top5_correct.sum(dim=-1).mean().item()\n",
    "\n",
    "    # Compute F1 score\n",
    "    metric_f1 = evaluate_load(\"f1\")\n",
    "    f1_score = metric_f1.compute(\n",
    "        predictions=predicted_classes.numpy(),\n",
    "        references=labels.numpy(),\n",
    "        average=\"weighted\",\n",
    "    )[\"f1\"]\n",
    "\n",
    "    return {\"accuracy\": accuracy, \"top5_accuracy\": top5_accuracy, \"f1_score\": f1_score}\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k)\n",
    "\n",
    "    num_map = {i: 0 for i in range(100)}\n",
    "    correct_map = {i: 0 for i in range(100)}\n",
    "    n_correct = correct[0].view(-1)\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        t = target[i].item()\n",
    "        num_map[t] += 1\n",
    "        if n_correct[i].item():\n",
    "            correct_map[t] += 1\n",
    "\n",
    "    return res, num_map, correct_map\n",
    "\n",
    "\n",
    "def cutmix_data(x, y, alpha=1.0):\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size)\n",
    "    y_a, y_b = y, y[index]\n",
    "    bbx1, bby1, bbx2, bby2 = rand_bbox(x.size(), lam)\n",
    "    x[:, :, bbx1:bbx2, bby1:bby2] = x[index, :, bbx1:bbx2, bby1:bby2]\n",
    "    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (x.size()[-1] * x.size()[-2]))\n",
    "    return x, y_a, y_b, lam\n",
    "\n",
    "\n",
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1.0 - lam)\n",
    "    cut_w = int(W * cut_rat)\n",
    "    cut_h = int(H * cut_rat)\n",
    "\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "\n",
    "def cutmix_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n",
    "\n",
    "class DOG100Dataset(Dataset):\n",
    "    def __init__(self, dataset, transform=None):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.dataset[idx]\n",
    "        image = item[\"pixel_values\"].convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return {\"pixel_values\": image, \"label\": item[\"label\"]}\n",
    "\n",
    "\n",
    "class CutMixCollator(DefaultDataCollator):\n",
    "    def __init__(self, cutmix_prob=0.5, cutmix_alpha=1.0):\n",
    "        self.cutmix_prob = cutmix_prob\n",
    "        self.cutmix_alpha = cutmix_alpha\n",
    "\n",
    "    def __call__(self, features, is_train=True):\n",
    "        batch = {}\n",
    "        pixel_values = torch.stack([f[\"pixel_values\"] for f in features])\n",
    "        labels = torch.tensor([f[\"label\"] for f in features])\n",
    "\n",
    "        if is_train and random.random() < self.cutmix_prob:\n",
    "            pixel_values, labels_a, labels_b, lam = cutmix_data(\n",
    "                pixel_values, labels, self.cutmix_alpha\n",
    "            )\n",
    "            batch[\"pixel_values\"] = pixel_values\n",
    "            batch[\"labels_a\"] = labels_a\n",
    "            batch[\"labels_b\"] = labels_b\n",
    "            batch[\"lam\"] = lam\n",
    "        else:\n",
    "            batch[\"pixel_values\"] = pixel_values\n",
    "            batch[\"label\"] = labels\n",
    "\n",
    "        return batch\n",
    "\n",
    "\n",
    "class CutMixTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        pixel_values = inputs[\"pixel_values\"]\n",
    "        labels = inputs.get(\"label\", None)\n",
    "\n",
    "        outputs = model(pixel_values)\n",
    "        loss_fct = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        if (\n",
    "            self.model.training\n",
    "            and \"labels_a\" in inputs\n",
    "            and \"labels_b\" in inputs\n",
    "            and \"lam\" in inputs\n",
    "        ):\n",
    "            labels_a = inputs[\"labels_a\"]\n",
    "            labels_b = inputs[\"labels_b\"]\n",
    "            lam = inputs[\"lam\"]\n",
    "            loss = cutmix_criterion(loss_fct, outputs.logits, labels_a, labels_b, lam)\n",
    "        else:\n",
    "            loss = loss_fct(outputs.logits, labels)\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog, labels, label2id, id2label = load_and_preprocess_data()\n",
    "checkpoint = \"microsoft/swin-tiny-patch4-window7-224\"\n",
    "image_processor = AutoImageProcessor.from_pretrained(checkpoint)\n",
    "transform = get_image_transforms()\n",
    "train_dataset = DOG100Dataset(dog[\"train\"], transform=transform)\n",
    "test_dataset = DOG100Dataset(dog[\"test\"], transform=transform)\n",
    "\n",
    "model = AutoModelForImageClassification.from_pretrained(\n",
    "        checkpoint,\n",
    "        num_labels=len(labels),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id,\n",
    "        ignore_mismatched_sizes=True\n",
    "\n",
    "    )\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "        output_dir=\"swin_dog_cutmix\",\n",
    "        remove_unused_columns=False,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        \n",
    "        learning_rate=5e-4,\n",
    "        per_device_train_batch_size=64,\n",
    "        gradient_accumulation_steps=4,\n",
    "        per_device_eval_batch_size=64,\n",
    "        num_train_epochs=5,\n",
    "        warmup_ratio=0.1,\n",
    "        logging_steps=10,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"accuracy\",\n",
    "        report_to=\"wandb\",\n",
    "        label_names=[\"label\"],\n",
    "    )\n",
    "\n",
    "trainer = CutMixTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        data_collator=lambda features: CutMixCollator(\n",
    "            cutmix_prob=0.5, cutmix_alpha=1.0\n",
    "        )(features, is_train=model.training),\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "        tokenizer=image_processor,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
